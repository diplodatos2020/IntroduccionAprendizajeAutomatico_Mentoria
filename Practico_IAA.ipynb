{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Practico Mentoria - Introduccion al Aprendizaje Automatico**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se propone la elaboración de un informe o presentación, en formato estatico:\n",
    "* PDF\n",
    "* Markdowns\n",
    "* Google Docs\n",
    "\n",
    "Que responda a las cuestiones solicitadas en cada seccion de esta **Jupyter Notebook**.\n",
    "\n",
    "La comunicación debe estar apuntada a un público técnico pero sin conocimiento del tema particular, como por ejemplo, sus compañeros de clase.  \n",
    "Por lo cual debe estar redactado de forma consisa y comprensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../Introduccion_Mentoria/dataset_inf_telec_20200501T130000_20200727T010000_v1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    filename,\n",
    "    dtype={\n",
    "        'ID_EQUIPO': int,\n",
    "        'PUNTO_MEDICION': str,\n",
    "        'CAPACIDAD_MAXIMA_GBS': float,\n",
    "        'PASO': int,\n",
    "        'LATENCIA_MS': float,\n",
    "        'PORCENTAJE_PACK_LOSS': float,\n",
    "        'INBOUND_BITS': np.float64,\n",
    "        'OUTBOUND_BITS': np.float64,\n",
    "        'MEDIDA': str,\n",
    "    },\n",
    "    parse_dates=[\n",
    "        'FECHA_INICIO_MEDICION',\n",
    "        'FECHA_HORA',\n",
    "        'FECHA_FIN_MEDICION',\n",
    "    ],\n",
    "    na_values=['NaN']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.FECHA_HORA.min())\n",
    "\n",
    "print(df.FECHA_HORA.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regresion**\n",
    "\n",
    "Elija algun `PUNTO MEDICION`, por ejemplo **ABA - Abasto Cliente**.\n",
    "\n",
    "Vamos a predecir el `LATENCIA_MS` de dicho punto de medición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos el \"target\" del resto del dataset\n",
    "X = df.loc[:, df.columns != 'LATENCIA_MS']\n",
    "y = df['LATENCIA_MS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos uno o más feature del dataset que no sea categórico, por ejemplo `INBOUND_BITS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modificar esta feature por algún otro (o una combinacion de estos) para ver como cambian los resultados\n",
    "X = X[['INBOUND_BITS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **División de datos en conjuntos de entrenamiento y evaluación**\n",
    "\n",
    "La primer tarea consiste en dividir el conjunto de datos cargados en el apartado anterior en conjuntos de entrenamiento (training) y evaluación (test).\n",
    "\n",
    "Utilizar aproximadamente 70% de los datos para entrenamiento y 30% para validación.\n",
    "\n",
    "Links:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **Regresion Lineal**\n",
    "\n",
    "Link:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el desempeño del clasificador utilizando la media del error cuadrado (`MSE` o `Mean Squared Error`) sobre el conjunto de datos de entrenamiento `(X_train, y_train)` y lo comparamos con el de validación `(X_val, y_test)`.\n",
    "Mientras más cercano a cero mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE para entrenamiento: {mean_squared_error(y_train, model.predict(X_train)):.2f}\")\n",
    "print(f\"MSE para validación   : {mean_squared_error(y_test, model.predict(X_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualizacion**\n",
    "\n",
    "**Warning**: Tener en cuenta que si son dos o mas features no se va a poder visualizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "X_range_start = np.min(np.r_[X_train, X_test])\n",
    "X_range_stop = np.max(np.r_[X_train, X_test])\n",
    "y_range_start = np.min(np.r_[y_train, y_test])\n",
    "y_range_stop = np.max(np.r_[y_train, y_test])\n",
    "X_linspace = np.linspace(X_range_start, X_range_stop, 200).reshape(-1, 1)\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train, y_train, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "plt.plot(X_linspace, model.predict(X_linspace), color=\"tomato\", label=\"modelo\")\n",
    "plt.ylim(y_range_start, y_range_stop)\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test, y_test, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "plt.plot(X_linspace, model.predict(X_linspace), color=\"tomato\", label=\"modelo\")\n",
    "plt.ylim(y_range_start, y_range_stop)\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **EXTRA: Regresión Polinomial**\n",
    "\n",
    "Link:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clasificacion**\n",
    "\n",
    "Elija algun `PUNTO MEDICION`, por ejemplo **ABA - Abasto Cliente**.\n",
    "\n",
    "Vamos a predecir el `PORCENTAJE_PACK_LOSS` de dicho punto de medición.  \n",
    "Como esta variable no es categorica, vamos a codificarla como tal (guiarse por lo que saben de **Analisis y Curacion de Datos**), para ello vamos a tomar los siguientes rangos:\n",
    "* Si `PORCENTAJE_PACK_LOSS` $\\in [0, 0.05) \\Rightarrow$ 0\n",
    "* Si `PORCENTAJE_PACK_LOSS` $\\in [0.05, 0.1) \\Rightarrow$ 1\n",
    "* Si `PORCENTAJE_PACK_LOSS` $\\in [0.1, \\infty) \\Rightarrow$ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos el \"target\" del resto del dataset\n",
    "X = df.loc[:, df.columns != 'PORCENTAJE_PACK_LOSS']\n",
    "y = df['PORCENTAJE_PACK_LOSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Codificar la variable `PORCENTAJE_PACK_LOSS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos uno o más feature del dataset que no sea categórico, por ejemplo `INBOUND_BITS` y `OUTBOUND_BITS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modificar esta feature por algún otro (o una combinacion de estos) para ver como cambian los resultados\n",
    "X = X[['INBOUND_BITS', 'OUTBOUND_BITS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **División de datos en conjuntos de entrenamiento y evaluación**\n",
    "\n",
    "La primer tarea consiste en dividir el conjunto de datos cargados en el apartado anterior en conjuntos de entrenamiento (training) y evaluación (test).\n",
    "\n",
    "Utilizar aproximadamente 70% de los datos para entrenamiento y 30% para validación.\n",
    "\n",
    "Links:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### **Regresion Logistica**\n",
    "\n",
    "Link:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = # TODO: Tipo de regularización: l1 (valor absoluto), l2 (cuadrados).\n",
    "alpha = # TODO: Parámetro de regularización. También denominado como parámetro `lambda`. Debe ser mayor que 0.\n",
    "\n",
    "model = LogisticRegression(penalty=penalty, C=1./alpha, multi_class='ovr')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy para entrenamiento: {accuracy_score(y_train, model.predict(X_train)):.2f}\")\n",
    "print(f\"Accuracy para validación   : {accuracy_score(y_test, model.predict(X_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Matriz de Confusion**\n",
    "\n",
    "Plotear las matrices de confunsion y obtener algunas conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
